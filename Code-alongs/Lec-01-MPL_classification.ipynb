{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "raw_data = load_breast_cancer()\n",
    "X, y = raw_data.data, raw_data.target\n",
    "\n",
    "print(f\"Any nans? {np.isnan(X).any()}\")\n",
    "X.shape, y.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Any nans? False\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train|test split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split( X, y, test_size =0.2,random_state=42 )\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train) \n",
    "scaled_X_test = scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer\n",
    "\n",
    "def MLP():\n",
    "    model = Sequential(name = \"MLP\")\n",
    "    model.add(InputLayer(X.shape[1], name = \"Input_layer\"))\n",
    "    model.add(Dense(32, name = \"Hidden1\", activation = \"relu\")) # change to he initializer\n",
    "    model.add(Dense(32, name = \"Hidden2\", activation = \"relu\"))\n",
    "    model.add(Dense(1, name = \"Output\", activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\")\n",
    "    return model\n",
    "\n",
    "print(f\"Training parameters {(30+1)*32+(33*32)+33}\")\n",
    "model = MLP()\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training parameters 2081\n",
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden1 (Dense)             (None, 32)                992       \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2022-04-25 12:44:40.064195: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model.fit(scaled_X_train, y_train, epochs = 500, validation_split=.2, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.7005 - val_loss: 0.5816\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.4963 - val_loss: 0.4186\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3661 - val_loss: 0.3134\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2716 - val_loss: 0.2430\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2071 - val_loss: 0.1956\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1641 - val_loss: 0.1641\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1352 - val_loss: 0.1442\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1151 - val_loss: 0.1306\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1004 - val_loss: 0.1208\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0896 - val_loss: 0.1135\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0801 - val_loss: 0.1087\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0730 - val_loss: 0.1064\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0670 - val_loss: 0.1048\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0619 - val_loss: 0.1033\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0588 - val_loss: 0.1015\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0547 - val_loss: 0.1019\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0522 - val_loss: 0.1026\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0491 - val_loss: 0.1012\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0469 - val_loss: 0.0992\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0446 - val_loss: 0.0989\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0420 - val_loss: 0.0990\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0401 - val_loss: 0.0987\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0386 - val_loss: 0.1001\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0366 - val_loss: 0.0981\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0351 - val_loss: 0.0985\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0335 - val_loss: 0.0980\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0326 - val_loss: 0.1000\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0308 - val_loss: 0.0996\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0294 - val_loss: 0.0997\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0285 - val_loss: 0.1003\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0272 - val_loss: 0.0996\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0263 - val_loss: 0.0999\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0250 - val_loss: 0.1008\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0240 - val_loss: 0.1016\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0230 - val_loss: 0.1014\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0222 - val_loss: 0.1020\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0212 - val_loss: 0.1025\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0204 - val_loss: 0.1032\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0194 - val_loss: 0.1037\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0187 - val_loss: 0.1045\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0178 - val_loss: 0.1048\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0170 - val_loss: 0.1043\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0164 - val_loss: 0.1040\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0156 - val_loss: 0.1042\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0149 - val_loss: 0.1051\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.0143 - val_loss: 0.1068\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0139 - val_loss: 0.1074\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0134 - val_loss: 0.1081\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0125 - val_loss: 0.1077\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0120 - val_loss: 0.1095\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0122 - val_loss: 0.1101\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0115 - val_loss: 0.1109\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0104 - val_loss: 0.1133\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0100 - val_loss: 0.1146\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0096 - val_loss: 0.1154\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0090 - val_loss: 0.1163\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0088 - val_loss: 0.1167\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0083 - val_loss: 0.1174\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0080 - val_loss: 0.1215\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0076 - val_loss: 0.1207\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0074 - val_loss: 0.1205\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0071 - val_loss: 0.1196\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0068 - val_loss: 0.1212\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0066 - val_loss: 0.1210\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0063 - val_loss: 0.1209\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 0.0059 - val_loss: 0.1221\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0058 - val_loss: 0.1244\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0056 - val_loss: 0.1243\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0053 - val_loss: 0.1254\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0052 - val_loss: 0.1284\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0050 - val_loss: 0.1295\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0047 - val_loss: 0.1304\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0046 - val_loss: 0.1304\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0044 - val_loss: 0.1325\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.0043 - val_loss: 0.1344\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0044 - val_loss: 0.1341\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 0.1355\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0039 - val_loss: 0.1382\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0038 - val_loss: 0.1420\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 0.1420\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 0.1378\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.1386\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0032 - val_loss: 0.1397\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0031 - val_loss: 0.1405\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0030 - val_loss: 0.1423\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0029 - val_loss: 0.1426\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0028 - val_loss: 0.1440\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.1438\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0026 - val_loss: 0.1473\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.1494\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0025 - val_loss: 0.1528\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.1532\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.1525\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0023 - val_loss: 0.1513\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0025 - val_loss: 0.1509\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.1509\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0021 - val_loss: 0.1507\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.1521\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.1509\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.1510\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.1530\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.1531\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0016 - val_loss: 0.1550\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 0.1558\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 0.1550\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0015 - val_loss: 0.1538\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 0.1531\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.1548\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0014 - val_loss: 0.1562\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 0.1564\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.1571\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0013 - val_loss: 0.1599\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.1613\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0012 - val_loss: 0.1607\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.1621\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.1618\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.1617\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.1626\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.1640\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0011 - val_loss: 0.1649\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 0.1649\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0010 - val_loss: 0.1657\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.8289e-04 - val_loss: 0.1674\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.6595e-04 - val_loss: 0.1669\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.5361e-04 - val_loss: 0.1674\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 9.1114e-04 - val_loss: 0.1679\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.9895e-04 - val_loss: 0.1701\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.7690e-04 - val_loss: 0.1705\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.5785e-04 - val_loss: 0.1710\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.5400e-04 - val_loss: 0.1712\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.3921e-04 - val_loss: 0.1710\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 8.0941e-04 - val_loss: 0.1708\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.8766e-04 - val_loss: 0.1702\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.7512e-04 - val_loss: 0.1722\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.5637e-04 - val_loss: 0.1727\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.4514e-04 - val_loss: 0.1729\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 7.2485e-04 - val_loss: 0.1723\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.1212e-04 - val_loss: 0.1729\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 6.9319e-04 - val_loss: 0.1740\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.8865e-04 - val_loss: 0.1749\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 6.7094e-04 - val_loss: 0.1748\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 6.5563e-04 - val_loss: 0.1755\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.4815e-04 - val_loss: 0.1761\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.2935e-04 - val_loss: 0.1813\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.4781e-04 - val_loss: 0.1817\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.2619e-04 - val_loss: 0.1808\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.9902e-04 - val_loss: 0.1808\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 5.8949e-04 - val_loss: 0.1800\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.6826e-04 - val_loss: 0.1807\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 5.5309e-04 - val_loss: 0.1833\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.5555e-04 - val_loss: 0.1833\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.4037e-04 - val_loss: 0.1822\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.2131e-04 - val_loss: 0.1823\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.1598e-04 - val_loss: 0.1829\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.0459e-04 - val_loss: 0.1852\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.9220e-04 - val_loss: 0.1851\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.8725e-04 - val_loss: 0.1854\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.7713e-04 - val_loss: 0.1855\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.7203e-04 - val_loss: 0.1867\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.6081e-04 - val_loss: 0.1871\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.5642e-04 - val_loss: 0.1870\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 4.4992e-04 - val_loss: 0.1882\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.3991e-04 - val_loss: 0.1875\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 4.3149e-04 - val_loss: 0.1881\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 4.2245e-04 - val_loss: 0.1883\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 4.1534e-04 - val_loss: 0.1896\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 4.1154e-04 - val_loss: 0.1893\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.0201e-04 - val_loss: 0.1888\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.9663e-04 - val_loss: 0.1890\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.9068e-04 - val_loss: 0.1915\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.8747e-04 - val_loss: 0.1923\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 3.7830e-04 - val_loss: 0.1921\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 3.6983e-04 - val_loss: 0.1915\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.6628e-04 - val_loss: 0.1914\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.5600e-04 - val_loss: 0.1932\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.5238e-04 - val_loss: 0.1925\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.4641e-04 - val_loss: 0.1925\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.3702e-04 - val_loss: 0.1935\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.3330e-04 - val_loss: 0.1933\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.2660e-04 - val_loss: 0.1950\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.2184e-04 - val_loss: 0.1954\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.1796e-04 - val_loss: 0.1951\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.1468e-04 - val_loss: 0.1951\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.0833e-04 - val_loss: 0.1973\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.1006e-04 - val_loss: 0.1981\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.0841e-04 - val_loss: 0.1979\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.9833e-04 - val_loss: 0.1987\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.9250e-04 - val_loss: 0.1986\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.8703e-04 - val_loss: 0.2025\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.8416e-04 - val_loss: 0.2029\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7924e-04 - val_loss: 0.2022\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.7045e-04 - val_loss: 0.2007\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.6558e-04 - val_loss: 0.2008\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.5716e-04 - val_loss: 0.2012\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.5862e-04 - val_loss: 0.1996\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.5738e-04 - val_loss: 0.1998\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 2.4789e-04 - val_loss: 0.2007\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.4505e-04 - val_loss: 0.2024\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.4002e-04 - val_loss: 0.2025\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.3750e-04 - val_loss: 0.2032\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3407e-04 - val_loss: 0.2033\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.3217e-04 - val_loss: 0.2063\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.3014e-04 - val_loss: 0.2055\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.2597e-04 - val_loss: 0.2055\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2416e-04 - val_loss: 0.2051\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 2.1734e-04 - val_loss: 0.2047\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.1492e-04 - val_loss: 0.2069\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.0996e-04 - val_loss: 0.2085\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.0686e-04 - val_loss: 0.2086\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.0476e-04 - val_loss: 0.2100\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.0487e-04 - val_loss: 0.2134\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.0220e-04 - val_loss: 0.2136\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.9926e-04 - val_loss: 0.2124\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 1.9173e-04 - val_loss: 0.2107\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.8973e-04 - val_loss: 0.2108\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 1.8670e-04 - val_loss: 0.2120\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.8364e-04 - val_loss: 0.2119\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.8172e-04 - val_loss: 0.2127\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.7932e-04 - val_loss: 0.2127\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.7657e-04 - val_loss: 0.2136\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 1.7435e-04 - val_loss: 0.2129\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 1.7186e-04 - val_loss: 0.2135\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.7133e-04 - val_loss: 0.2139\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.6905e-04 - val_loss: 0.2143\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.6610e-04 - val_loss: 0.2144\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.6405e-04 - val_loss: 0.2149\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.6161e-04 - val_loss: 0.2152\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.5946e-04 - val_loss: 0.2154\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5767e-04 - val_loss: 0.2160\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.5558e-04 - val_loss: 0.2160\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.5645e-04 - val_loss: 0.2167\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 1.5251e-04 - val_loss: 0.2170\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.4936e-04 - val_loss: 0.2170\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.4726e-04 - val_loss: 0.2169\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.4590e-04 - val_loss: 0.2175\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.4480e-04 - val_loss: 0.2172\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.4217e-04 - val_loss: 0.2177\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.4065e-04 - val_loss: 0.2175\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.3945e-04 - val_loss: 0.2190\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.3774e-04 - val_loss: 0.2181\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3587e-04 - val_loss: 0.2179\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 1.3624e-04 - val_loss: 0.2182\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.3312e-04 - val_loss: 0.2186\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3151e-04 - val_loss: 0.2193\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.2887e-04 - val_loss: 0.2194\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.2947e-04 - val_loss: 0.2199\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.2676e-04 - val_loss: 0.2223\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.2631e-04 - val_loss: 0.2228\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.2519e-04 - val_loss: 0.2229\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.2658e-04 - val_loss: 0.2231\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.2247e-04 - val_loss: 0.2228\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1962e-04 - val_loss: 0.2226\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.1827e-04 - val_loss: 0.2237\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1669e-04 - val_loss: 0.2240\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1541e-04 - val_loss: 0.2240\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1485e-04 - val_loss: 0.2247\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.1365e-04 - val_loss: 0.2249\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1116e-04 - val_loss: 0.2247\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.0969e-04 - val_loss: 0.2256\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 1.0845e-04 - val_loss: 0.2260\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.0711e-04 - val_loss: 0.2261\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.0588e-04 - val_loss: 0.2266\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.0512e-04 - val_loss: 0.2277\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 1.0555e-04 - val_loss: 0.2278\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.0351e-04 - val_loss: 0.2278\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.0322e-04 - val_loss: 0.2277\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.0124e-04 - val_loss: 0.2273\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.9707e-05 - val_loss: 0.2286\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.7933e-05 - val_loss: 0.2284\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.7428e-05 - val_loss: 0.2288\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 9.5514e-05 - val_loss: 0.2287\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.4284e-05 - val_loss: 0.2297\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.3683e-05 - val_loss: 0.2294\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.3301e-05 - val_loss: 0.2306\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.1493e-05 - val_loss: 0.2312\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.0772e-05 - val_loss: 0.2312\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.9111e-05 - val_loss: 0.2320\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.8454e-05 - val_loss: 0.2321\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 8.7359e-05 - val_loss: 0.2320\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.6756e-05 - val_loss: 0.2326\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.5438e-05 - val_loss: 0.2326\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.4991e-05 - val_loss: 0.2328\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.4843e-05 - val_loss: 0.2338\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.3365e-05 - val_loss: 0.2341\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.2678e-05 - val_loss: 0.2342\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.1381e-05 - val_loss: 0.2350\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.0833e-05 - val_loss: 0.2348\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 7.9802e-05 - val_loss: 0.2355\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7.8959e-05 - val_loss: 0.2349\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.8133e-05 - val_loss: 0.2357\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.6911e-05 - val_loss: 0.2356\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.7155e-05 - val_loss: 0.2351\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.5940e-05 - val_loss: 0.2357\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.4541e-05 - val_loss: 0.2370\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 7.5146e-05 - val_loss: 0.2383\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 7.4725e-05 - val_loss: 0.2384\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.3141e-05 - val_loss: 0.2380\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 7.1713e-05 - val_loss: 0.2380\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.2221e-05 - val_loss: 0.2383\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.2171e-05 - val_loss: 0.2410\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.0809e-05 - val_loss: 0.2406\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.9444e-05 - val_loss: 0.2408\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.8338e-05 - val_loss: 0.2405\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 6.7518e-05 - val_loss: 0.2406\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.6485e-05 - val_loss: 0.2410\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.5847e-05 - val_loss: 0.2412\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 6.5329e-05 - val_loss: 0.2426\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.4815e-05 - val_loss: 0.2424\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 6.3876e-05 - val_loss: 0.2422\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.2993e-05 - val_loss: 0.2421\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.2145e-05 - val_loss: 0.2423\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 6.1402e-05 - val_loss: 0.2437\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.1119e-05 - val_loss: 0.2437\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 6.0309e-05 - val_loss: 0.2431\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 5.9827e-05 - val_loss: 0.2438\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.9235e-05 - val_loss: 0.2440\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 5.8463e-05 - val_loss: 0.2441\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 5.9712e-05 - val_loss: 0.2436\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.7474e-05 - val_loss: 0.2446\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.6879e-05 - val_loss: 0.2452\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.6032e-05 - val_loss: 0.2452\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.5531e-05 - val_loss: 0.2459\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.5394e-05 - val_loss: 0.2458\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.4522e-05 - val_loss: 0.2460\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.4090e-05 - val_loss: 0.2467\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.3382e-05 - val_loss: 0.2470\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.3051e-05 - val_loss: 0.2473\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.2641e-05 - val_loss: 0.2475\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.2001e-05 - val_loss: 0.2477\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 5.1474e-05 - val_loss: 0.2483\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.0905e-05 - val_loss: 0.2477\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.0443e-05 - val_loss: 0.2481\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.0001e-05 - val_loss: 0.2491\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.9790e-05 - val_loss: 0.2500\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.9225e-05 - val_loss: 0.2496\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.8529e-05 - val_loss: 0.2498\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.8563e-05 - val_loss: 0.2494\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 4.7876e-05 - val_loss: 0.2505\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 4.7356e-05 - val_loss: 0.2503\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.8172e-05 - val_loss: 0.2507\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.6371e-05 - val_loss: 0.2511\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.6055e-05 - val_loss: 0.2518\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.5414e-05 - val_loss: 0.2519\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.5172e-05 - val_loss: 0.2530\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.4675e-05 - val_loss: 0.2533\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.4284e-05 - val_loss: 0.2535\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.3910e-05 - val_loss: 0.2539\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.3667e-05 - val_loss: 0.2545\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 4.2959e-05 - val_loss: 0.2545\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.2512e-05 - val_loss: 0.2547\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.2023e-05 - val_loss: 0.2546\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.1704e-05 - val_loss: 0.2545\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.1323e-05 - val_loss: 0.2545\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.1046e-05 - val_loss: 0.2552\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 4.1073e-05 - val_loss: 0.2540\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.0153e-05 - val_loss: 0.2547\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.9852e-05 - val_loss: 0.2549\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.9608e-05 - val_loss: 0.2548\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.9375e-05 - val_loss: 0.2549\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.8725e-05 - val_loss: 0.2560\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 3.8601e-05 - val_loss: 0.2567\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.7939e-05 - val_loss: 0.2560\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.7900e-05 - val_loss: 0.2567\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.7495e-05 - val_loss: 0.2573\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 3.7060e-05 - val_loss: 0.2579\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.6834e-05 - val_loss: 0.2577\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 3.6684e-05 - val_loss: 0.2579\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 3.6037e-05 - val_loss: 0.2592\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.5705e-05 - val_loss: 0.2596\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.5476e-05 - val_loss: 0.2594\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.5122e-05 - val_loss: 0.2597\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.4765e-05 - val_loss: 0.2601\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.4417e-05 - val_loss: 0.2600\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 3.4202e-05 - val_loss: 0.2601\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.4556e-05 - val_loss: 0.2596\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 3.3842e-05 - val_loss: 0.2619\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.3120e-05 - val_loss: 0.2608\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.2851e-05 - val_loss: 0.2605\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.2531e-05 - val_loss: 0.2612\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.2140e-05 - val_loss: 0.2615\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 3.1777e-05 - val_loss: 0.2617\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 3.1710e-05 - val_loss: 0.2616\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.1421e-05 - val_loss: 0.2626\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 3.1067e-05 - val_loss: 0.2633\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 3.0711e-05 - val_loss: 0.2637\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 3.0369e-05 - val_loss: 0.2634\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 3.0308e-05 - val_loss: 0.2638\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.9945e-05 - val_loss: 0.2642\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.9697e-05 - val_loss: 0.2645\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.9454e-05 - val_loss: 0.2648\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.9081e-05 - val_loss: 0.2654\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.8953e-05 - val_loss: 0.2658\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.8578e-05 - val_loss: 0.2659\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 2.8441e-05 - val_loss: 0.2661\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.8327e-05 - val_loss: 0.2656\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.7916e-05 - val_loss: 0.2663\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.7772e-05 - val_loss: 0.2666\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.7617e-05 - val_loss: 0.2663\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.7184e-05 - val_loss: 0.2661\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.6980e-05 - val_loss: 0.2666\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.6753e-05 - val_loss: 0.2671\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.6451e-05 - val_loss: 0.2670\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.6149e-05 - val_loss: 0.2675\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.6029e-05 - val_loss: 0.2663\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.5814e-05 - val_loss: 0.2670\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.5536e-05 - val_loss: 0.2677\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5570e-05 - val_loss: 0.2677\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 2.5231e-05 - val_loss: 0.2696\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.5304e-05 - val_loss: 0.2696\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.4889e-05 - val_loss: 0.2696\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.4503e-05 - val_loss: 0.2694\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 2.4340e-05 - val_loss: 0.2690\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.3950e-05 - val_loss: 0.2704\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 2.3844e-05 - val_loss: 0.2707\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.3663e-05 - val_loss: 0.2706\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.3250e-05 - val_loss: 0.2707\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.3105e-05 - val_loss: 0.2705\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.2982e-05 - val_loss: 0.2702\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.2909e-05 - val_loss: 0.2710\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.2610e-05 - val_loss: 0.2710\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.2317e-05 - val_loss: 0.2710\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.2291e-05 - val_loss: 0.2709\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 2.1950e-05 - val_loss: 0.2719\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.1789e-05 - val_loss: 0.2724\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.1690e-05 - val_loss: 0.2723\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.1394e-05 - val_loss: 0.2717\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 2.1275e-05 - val_loss: 0.2720\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 2.1038e-05 - val_loss: 0.2728\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.1053e-05 - val_loss: 0.2738\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.0658e-05 - val_loss: 0.2741\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.0430e-05 - val_loss: 0.2743\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 2.0421e-05 - val_loss: 0.2745\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 2.0085e-05 - val_loss: 0.2752\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 18ms/step - loss: 1.9964e-05 - val_loss: 0.2751\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.9789e-05 - val_loss: 0.2750\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.9598e-05 - val_loss: 0.2755\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.9548e-05 - val_loss: 0.2762\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.9361e-05 - val_loss: 0.2764\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 1.9178e-05 - val_loss: 0.2777\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.9057e-05 - val_loss: 0.2774\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.8921e-05 - val_loss: 0.2773\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 1.8763e-05 - val_loss: 0.2771\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.8485e-05 - val_loss: 0.2768\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.8327e-05 - val_loss: 0.2770\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.8199e-05 - val_loss: 0.2776\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 1.8045e-05 - val_loss: 0.2773\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 1.7918e-05 - val_loss: 0.2772\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.7734e-05 - val_loss: 0.2781\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.7713e-05 - val_loss: 0.2792\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.7559e-05 - val_loss: 0.2787\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.7373e-05 - val_loss: 0.2786\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.7186e-05 - val_loss: 0.2791\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.7127e-05 - val_loss: 0.2795\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.6931e-05 - val_loss: 0.2793\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.6819e-05 - val_loss: 0.2794\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.6778e-05 - val_loss: 0.2795\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.6584e-05 - val_loss: 0.2800\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.6380e-05 - val_loss: 0.2798\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.6263e-05 - val_loss: 0.2801\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.6186e-05 - val_loss: 0.2810\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.6025e-05 - val_loss: 0.2805\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.5950e-05 - val_loss: 0.2808\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.5719e-05 - val_loss: 0.2813\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.5579e-05 - val_loss: 0.2815\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 1.5458e-05 - val_loss: 0.2817\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.5381e-05 - val_loss: 0.2820\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 1.5216e-05 - val_loss: 0.2823\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.5108e-05 - val_loss: 0.2817\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4978e-05 - val_loss: 0.2818\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4852e-05 - val_loss: 0.2824\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.4726e-05 - val_loss: 0.2832\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.4654e-05 - val_loss: 0.2839\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.4543e-05 - val_loss: 0.2831\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4419e-05 - val_loss: 0.2833\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 1.4306e-05 - val_loss: 0.2829\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4218e-05 - val_loss: 0.2837\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.4087e-05 - val_loss: 0.2834\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3995e-05 - val_loss: 0.2843\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3768e-05 - val_loss: 0.2848\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3731e-05 - val_loss: 0.2848\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3557e-05 - val_loss: 0.2850\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.3519e-05 - val_loss: 0.2846\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.3422e-05 - val_loss: 0.2854\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 1.3264e-05 - val_loss: 0.2860\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 1.3182e-05 - val_loss: 0.2863\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 1.3061e-05 - val_loss: 0.2862\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.2918e-05 - val_loss: 0.2860\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 1.2824e-05 - val_loss: 0.2864\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2708e-05 - val_loss: 0.2864\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2579e-05 - val_loss: 0.2862\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2543e-05 - val_loss: 0.2864\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.2395e-05 - val_loss: 0.2866\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.2378e-05 - val_loss: 0.2879\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.2226e-05 - val_loss: 0.2880\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.2116e-05 - val_loss: 0.2877\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 1.2024e-05 - val_loss: 0.2877\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 1.1986e-05 - val_loss: 0.2880\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 1.1844e-05 - val_loss: 0.2885\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1706e-05 - val_loss: 0.2884\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 1.1694e-05 - val_loss: 0.2880\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8608cb4970>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_loss = pd.DataFrame(model.history.history)\n",
    "df_loss.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.700495</td>\n",
       "      <td>0.581556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.496348</td>\n",
       "      <td>0.418580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.366148</td>\n",
       "      <td>0.313420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.271560</td>\n",
       "      <td>0.242977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.207058</td>\n",
       "      <td>0.195643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  val_loss\n",
       "0  0.700495  0.581556\n",
       "1  0.496348  0.418580\n",
       "2  0.366148  0.313420\n",
       "3  0.271560  0.242977\n",
       "4  0.207058  0.195643"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_loss.plot()\n",
    "# clear overfitting as validation loss increases after a certain amount of epochs"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Early stopping"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = MLP()\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"MLP\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden1 (Dense)             (None, 32)                992       \n",
      "                                                                 \n",
      " Hidden2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " Output (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,081\n",
      "Trainable params: 2,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.fit(scaled_X_train, y_train, epochs = 50, validation_split=.2, verbose=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 25ms/step - loss: 0.5783 - val_loss: 0.4623\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.3897 - val_loss: 0.3109\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.2703 - val_loss: 0.2241\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.1981 - val_loss: 0.1751\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1547 - val_loss: 0.1463\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.1268 - val_loss: 0.1293\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1080 - val_loss: 0.1182\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.0948 - val_loss: 0.1098\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.0840 - val_loss: 0.1044\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.0765 - val_loss: 0.1011\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0706 - val_loss: 0.0980\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0657 - val_loss: 0.0955\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0612 - val_loss: 0.0943\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0575 - val_loss: 0.0928\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.0541 - val_loss: 0.0923\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0510 - val_loss: 0.0919\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0484 - val_loss: 0.0900\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0456 - val_loss: 0.0892\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0434 - val_loss: 0.0887\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0411 - val_loss: 0.0889\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0388 - val_loss: 0.0876\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0372 - val_loss: 0.0875\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0352 - val_loss: 0.0879\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0335 - val_loss: 0.0879\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0321 - val_loss: 0.0876\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0305 - val_loss: 0.0864\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0293 - val_loss: 0.0852\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0276 - val_loss: 0.0855\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0266 - val_loss: 0.0871\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0253 - val_loss: 0.0863\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0242 - val_loss: 0.0858\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0230 - val_loss: 0.0862\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0220 - val_loss: 0.0860\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0209 - val_loss: 0.0864\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0200 - val_loss: 0.0860\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0192 - val_loss: 0.0820\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0183 - val_loss: 0.0862\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0172 - val_loss: 0.0856\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0164 - val_loss: 0.0868\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0156 - val_loss: 0.0861\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0150 - val_loss: 0.0862\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.0142 - val_loss: 0.0863\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0134 - val_loss: 0.0855\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.0128 - val_loss: 0.0871\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.0123 - val_loss: 0.0870\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0116 - val_loss: 0.0867\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.0111 - val_loss: 0.0867\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0106 - val_loss: 0.0870\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0103 - val_loss: 0.0899\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.0098 - val_loss: 0.0886\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85ea4b1c70>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "pd.DataFrame(model.history.history).plot()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "model = MLP()\n",
    "model.fit(scaled_X_train, y_train, epochs = 50, verbose=0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85eaeeabb0>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction and evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = model.predict(scaled_X_test)\n",
    "y_pred = (y_pred > .5)*1\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        43\n",
      "           1       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('Deep-Learning-SAMI-FATMI-zzaYGOY0': pipenv)"
  },
  "interpreter": {
   "hash": "8407f01bccb437f997184224eb38d8a75620304536ca4faa0deeeb8f03fd3306"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}